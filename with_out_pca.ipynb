{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'weatherAUS.csv'\n",
    "Aus_weather = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coastal_cities = ['Adelaide', 'Albany', 'Brisbane', 'Cairns', 'CoffsHarbour', \n",
    "#                   'Darwin', 'GoldCoast', 'Hobart', 'Melbourne', 'MelbourneAirport',\n",
    "#                   'Newcastle', 'NorahHead', 'NorfolkIsland', 'Perth', 'PerthAirport',\n",
    "#                   'Portland', 'Sydney', 'SydneyAirport', 'Townsville', 'Williamtown', 'Wollongong']\n",
    "# Aus_weather = Aus_weather[Aus_weather['Location'].isin(coastal_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
       "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
       "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
       "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
       "       'Temp3pm', 'RainToday', 'RainTomorrow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aus_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aus_weather['Date'] = pd.to_datetime(Aus_weather['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return 'Winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aus_weather['Season'] = Aus_weather['Date'].apply(get_season)\n",
    "df_spring = Aus_weather[Aus_weather['Season'] == 'Spring']\n",
    "df_summer = Aus_weather[Aus_weather['Season'] == 'Summer']\n",
    "df_autumn = Aus_weather[Aus_weather['Season'] == 'Autumn']\n",
    "df_winter = Aus_weather[Aus_weather['Season'] == 'Winter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38264, 36737, 35337, 35122)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_spring), len(df_summer), len(df_autumn), len(df_winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_weather_data(df):\n",
    "    # Impute missing values for numerical columns\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    imputer_num = SimpleImputer(strategy='median')\n",
    "    df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
    "\n",
    "    # Drop certain categorical columns\n",
    "    df = df.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'Date', 'Season'], axis=1)\n",
    "\n",
    "    # Impute missing values for remaining categorical columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    for column in cat_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "        label_encoders[column] = label_encoder\n",
    "\n",
    "    return df, label_encoders\n",
    "processed_weather_data, encoders = preprocess_weather_data(df_winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir',\n",
       "       'WindGustSpeed', 'WindDir9am', 'WindDir3pm', 'WindSpeed9am',\n",
       "       'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am',\n",
       "       'Pressure3pm', 'Temp9am', 'Temp3pm', 'RainToday', 'RainTomorrow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_weather_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>13</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145338</th>\n",
       "      <td>19.3</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145339</th>\n",
       "      <td>18.1</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.2</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>34.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145340</th>\n",
       "      <td>19.3</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1013.7</td>\n",
       "      <td>1009.4</td>\n",
       "      <td>27.1</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145341</th>\n",
       "      <td>17.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>28.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1013.5</td>\n",
       "      <td>1009.6</td>\n",
       "      <td>26.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145342</th>\n",
       "      <td>15.9</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>28.3</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35122 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MinTemp  MaxTemp  Rainfall  WindGustDir  WindGustSpeed  WindDir9am  \\\n",
       "0          13.4     22.9       0.6           13           44.0          13   \n",
       "1           7.4     25.1       0.0           14           44.0           6   \n",
       "2          12.9     25.7       0.0           15           46.0          13   \n",
       "3           9.2     28.0       0.0            4           24.0           9   \n",
       "4          17.5     32.3       1.0           13           41.0           1   \n",
       "...         ...      ...       ...          ...            ...         ...   \n",
       "145338     19.3     36.7       0.0            9           50.0           0   \n",
       "145339     18.1     35.9       0.0            0           43.0           2   \n",
       "145340     19.3     37.5       0.0            2           37.0           0   \n",
       "145341     17.5     38.0       0.0           10           37.0           0   \n",
       "145342     15.9     38.2       0.0           10           37.0           0   \n",
       "\n",
       "        WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n",
       "0               14          20.0          24.0         71.0         22.0   \n",
       "1               15           4.0          22.0         44.0         25.0   \n",
       "2               15          19.0          26.0         38.0         30.0   \n",
       "3                0          11.0           9.0         45.0         16.0   \n",
       "4                7           7.0          20.0         82.0         33.0   \n",
       "...            ...           ...           ...          ...          ...   \n",
       "145338           9          30.0          17.0         29.0         15.0   \n",
       "145339           1          26.0          20.0         29.0         16.0   \n",
       "145340           1          24.0          17.0         23.0         13.0   \n",
       "145341          11          28.0          11.0         18.0         10.0   \n",
       "145342          10          15.0          19.0         15.0          8.0   \n",
       "\n",
       "        Pressure9am  Pressure3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  \n",
       "0            1007.7       1007.1     16.9     21.8          0             0  \n",
       "1            1010.6       1007.8     17.2     24.3          0             0  \n",
       "2            1007.6       1008.7     21.0     23.2          0             0  \n",
       "3            1017.6       1012.8     18.1     26.5          0             0  \n",
       "4            1010.8       1006.0     17.8     29.7          0             0  \n",
       "...             ...          ...      ...      ...        ...           ...  \n",
       "145338       1019.4       1014.6     26.3     35.0          0             0  \n",
       "145339       1017.2       1012.9     25.8     34.3          0             0  \n",
       "145340       1013.7       1009.4     27.1     36.3          0             0  \n",
       "145341       1013.5       1009.6     26.8     36.8          0             0  \n",
       "145342       1012.5       1008.8     28.3     37.8          0             0  \n",
       "\n",
       "[35122 rows x 17 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_weather_data.drop(['MinTemp','MaxTemp','WindGustDir','WindDir3pm','WindDir9am','Pressure9am',\n",
    "#        'Pressure3pm','Location'],axis=1)\n",
    "processed_weather_data.drop(['Location'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = processed_weather_data.drop(['RainTomorrow'], axis=1)\n",
    "y = processed_weather_data['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      5676\n",
      "           1       0.73      0.45      0.55      1349\n",
      "\n",
      "    accuracy                           0.86      7025\n",
      "   macro avg       0.80      0.70      0.74      7025\n",
      "weighted avg       0.85      0.86      0.85      7025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "model = RandomForestClassifier(**best_params,random_state=42)\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# y_pred_pca = model.predict(X_test_pca)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "# classification_rep_pca = classification_report(y_test, y_pred_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred)\n",
    "classification_rep_pca = classification_report(y_test, y_pred)\n",
    "print(classification_rep_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      5676\n",
      "           1       0.72      0.47      0.57      1349\n",
      "\n",
      "    accuracy                           0.86      7025\n",
      "   macro avg       0.80      0.72      0.75      7025\n",
      "weighted avg       0.85      0.86      0.85      7025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=200, learning_rate=0.1, max_depth=5)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep_pca = classification_report(y_test, y_pred)\n",
    "print(classification_rep_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming coastal_data is your preprocessed dataset\n",
    "\n",
    "\n",
    "# Split the data into training and test sets (70% training, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32))\n",
    "X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model definition\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train_scaled.shape[1], 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()  # Adjusting the output shape\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs).squeeze()  # Adjusting the output shape\n",
    "        y_pred.extend(outputs.round().numpy())\n",
    "\n",
    "# Convert predictions to a format suitable for classification report\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "\n",
    "# Compute classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
