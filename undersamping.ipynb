{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145460, 23)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'weatherAUS.csv'\n",
    "Aus_weather = pd.read_csv(file_path)\n",
    "Aus_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aus_weather['Date'] = pd.to_datetime(Aus_weather['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(date):\n",
    "    month = date.month\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return 'Winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aus_weather['Season'] = Aus_weather['Date'].apply(get_season)\n",
    "df_spring = Aus_weather[Aus_weather['Season'] == 'Spring']\n",
    "df_summer = Aus_weather[Aus_weather['Season'] == 'Summer']\n",
    "df_autumn = Aus_weather[Aus_weather['Season'] == 'Autumn']\n",
    "df_winter = Aus_weather[Aus_weather['Season'] == 'Winter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38264, 36737, 35337, 35122)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_spring), len(df_summer), len(df_autumn), len(df_winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_weather_data(df):\n",
    "    # Impute missing values for numerical columns\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    imputer_num = SimpleImputer(strategy='median')\n",
    "    df[num_cols] = imputer_num.fit_transform(df[num_cols])\n",
    "\n",
    "    # Drop certain categorical columns\n",
    "    df = df.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'Date', 'Season'], axis=1)\n",
    "\n",
    "    # Impute missing values for remaining categorical columns\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "    df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
    "\n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    for column in cat_cols:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
    "        label_encoders[column] = label_encoder\n",
    "\n",
    "    return df, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(data, target, i):\n",
    "    data, _ = preprocess_weather_data(data)\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    tl = TomekLinks()\n",
    "    X_resampled, y_resampled = tl.fit_resample(X, y)\n",
    "    resampled_data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    resampled_data[target] = y_resampled\n",
    "    resampled_data.to_csv(f'{i}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonable_datas = [df_spring, df_summer, df_autumn, df_winter]\n",
    "for i in range(4):\n",
    "    undersampling(seasonable_datas[i], 'RainTomorrow', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31877, 19)\n",
      "(107654, 19)\n"
     ]
    }
   ],
   "source": [
    "resampled_df = pd.read_csv('weatherAUS_resampled.csv')\n",
    "resampled_df.shape\n",
    "print(resampled_df[resampled_df['RainTomorrow']==1].shape)\n",
    "print(resampled_df[resampled_df['RainTomorrow']==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resampled_df.drop(['RainTomorrow'], axis=1)\n",
    "y = resampled_df['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91     21436\n",
      "           1       0.77      0.53      0.63      6471\n",
      "\n",
      "    accuracy                           0.86     27907\n",
      "   macro avg       0.82      0.74      0.77     27907\n",
      "weighted avg       0.85      0.86      0.85     27907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "model = RandomForestClassifier(**best_params,random_state=42)\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# y_pred_pca = model.predict(X_test_pca)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "# classification_rep_pca = classification_report(y_test, y_pred_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred)\n",
    "classification_rep_pca = classification_report(y_test, y_pred)\n",
    "print(classification_rep_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      5397\n",
      "           1       0.77      0.52      0.62      1371\n",
      "\n",
      "    accuracy                           0.87      6768\n",
      "   macro avg       0.83      0.74      0.77      6768\n",
      "weighted avg       0.86      0.87      0.86      6768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=200, learning_rate=0.1, max_depth=5)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep_pca = classification_report(y_test, y_pred)\n",
    "print(classification_rep_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6955, 18)\n",
      "(26884, 18)\n"
     ]
    }
   ],
   "source": [
    "spring_df = pd.read_csv('3.csv')\n",
    "print(spring_df[spring_df['RainTomorrow']==1].shape)\n",
    "print(spring_df[spring_df['RainTomorrow']==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spring_df.drop(['RainTomorrow'], axis=1)\n",
    "y = spring_df['RainTomorrow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      5397\n",
      "           1       0.76      0.48      0.58      1371\n",
      "\n",
      "    accuracy                           0.86      6768\n",
      "   macro avg       0.82      0.72      0.75      6768\n",
      "weighted avg       0.85      0.86      0.85      6768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "model = RandomForestClassifier(**best_params,random_state=42)\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# y_pred_pca = model.predict(X_test_pca)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "# classification_rep_pca = classification_report(y_test, y_pred_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred)\n",
    "classification_rep_pca = classification_report(y_test, y_pred)\n",
    "print(classification_rep_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      5397\n",
      "           1       0.77      0.52      0.62      1371\n",
      "\n",
      "    accuracy                           0.87      6768\n",
      "   macro avg       0.83      0.74      0.77      6768\n",
      "weighted avg       0.86      0.87      0.86      6768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=200, learning_rate=0.1, max_depth=5)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# model.fit(X_train_pca, y_train)\n",
    "# y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep_pca = classification_report(y_test, y_pred)\n",
    "print(classification_rep_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
