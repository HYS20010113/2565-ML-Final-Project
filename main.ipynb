{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'weatherAUS.csv'\n",
    "# Loading the dataset again to work with the original 'Location' values (string names)\n",
    "weather_data = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9058</th>\n",
       "      <td>427</td>\n",
       "      <td>11</td>\n",
       "      <td>16.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>1002.3</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9059</th>\n",
       "      <td>428</td>\n",
       "      <td>11</td>\n",
       "      <td>22.8</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1010.9</td>\n",
       "      <td>1011.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9060</th>\n",
       "      <td>429</td>\n",
       "      <td>11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1019.3</td>\n",
       "      <td>1018.8</td>\n",
       "      <td>21.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9061</th>\n",
       "      <td>430</td>\n",
       "      <td>11</td>\n",
       "      <td>14.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>431</td>\n",
       "      <td>11</td>\n",
       "      <td>15.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date  Location  MinTemp  MaxTemp  Rainfall  WindGustDir  WindGustSpeed   \n",
       "9058   427        11     16.1     31.4       0.0            5           54.0  \\\n",
       "9059   428        11     22.8     24.7       0.0           11           56.0   \n",
       "9060   429        11     20.0     24.1       4.6            9           35.0   \n",
       "9061   430        11     14.8     25.0       0.8            0           24.0   \n",
       "9062   431        11     15.5     27.3       0.0            4           41.0   \n",
       "\n",
       "      WindDir9am  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am   \n",
       "9058           3           5           7.0          37.0         51.0  \\\n",
       "9059          11           8          35.0          15.0         68.0   \n",
       "9060           9           0          20.0          19.0         70.0   \n",
       "9061          10           2           7.0          17.0         62.0   \n",
       "9062           7           4           7.0          30.0         54.0   \n",
       "\n",
       "      Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm  RainToday   \n",
       "9058         58.0       1005.9       1002.3     26.5     28.4          0  \\\n",
       "9059         67.0       1010.9       1011.4     23.4     24.4          0   \n",
       "9060         59.0       1019.3       1018.8     21.7     23.7          1   \n",
       "9061         45.0       1019.5       1017.0     22.5     24.8          0   \n",
       "9062         62.0       1015.7       1012.7     24.6     26.1          0   \n",
       "\n",
       "      RainTomorrow  \n",
       "9058             0  \n",
       "9059             1  \n",
       "9060             0  \n",
       "9061             0  \n",
       "9062             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing steps for the whole dataset\n",
    "\n",
    "# # Dropping 'row ID' as it's not needed for model training\n",
    "# weather_data = weather_data.drop(['row ID'], axis=1)\n",
    "\n",
    "# Handling missing values for numerical columns\n",
    "num_cols = weather_data.select_dtypes(include=[np.number]).columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "weather_data[num_cols] = imputer_num.fit_transform(weather_data[num_cols])\n",
    "\n",
    "# Handling missing values for categorical columns\n",
    "# For now, we will drop columns with a high percentage of missing values\n",
    "weather_data = weather_data.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1)\n",
    "cat_cols = weather_data.select_dtypes(include=['object']).columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "weather_data[cat_cols] = imputer_cat.fit_transform(weather_data[cat_cols])\n",
    "\n",
    "\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for column in cat_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    weather_data[column] = label_encoder.fit_transform(weather_data[column].astype(str))\n",
    "    label_encoders[column] = label_encoder\n",
    "\n",
    "# Adjusting the provided code to extract data for all coastal cities in Australia\n",
    "\n",
    "# First, let's define the coastal cities as per the original dataset\n",
    "coastal_cities = ['Adelaide', 'Albany', 'Brisbane', 'Cairns', 'CoffsHarbour', \n",
    "                  'Darwin', 'GoldCoast', 'Hobart', 'Melbourne', 'MelbourneAirport',\n",
    "                  'Newcastle', 'NorahHead', 'NorfolkIsland', 'Perth', 'PerthAirport',\n",
    "                  'Portland', 'Sydney', 'SydneyAirport', 'Townsville', 'Williamtown', 'Wollongong']\n",
    "\n",
    "# Now, let's extract the encoded values for these coastal cities\n",
    "encoded_coastal_cities = {label_encoders['Location'].transform([city])[0] for city in coastal_cities if city in label_encoders['Location'].classes_}\n",
    "\n",
    "# Extracting data for these coastal cities\n",
    "coastal_data = weather_data[weather_data['Location'].isin(encoded_coastal_cities)]\n",
    "\n",
    "# Overview of the processed coastal cities data\n",
    "coastal_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the encoded integer values back to their original string labels in 'Location' column\n",
    "location_mappings = {index: label for index, label in enumerate(label_encoders['Location'].classes_)}\n",
    "# location_mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training set size': 45365,\n",
       " 'Validation set size': 9721,\n",
       " 'Test set size': 9722}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow']\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "# Using 70% of data for training, 15% for validation, and 15% for testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "# Sizes of each dataset\n",
    "sizes = {\n",
    "    \"Training set size\": X_train.shape[0],\n",
    "    \"Validation set size\": X_val.shape[0],\n",
    "    \"Test set size\": X_test.shape[0]\n",
    "}\n",
    "\n",
    "sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'] # Norm used in the penalization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "logreg_optimized = LogisticRegression(**best_params, solver='liblinear', random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search:\", best_params)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set:\", best_score)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Model on Test Set:\", accuracy)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Optimized Model on New Test Set: 0.8133262823902697\n",
      "Classification Report for New Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      9765\n",
      "           1       0.73      0.46      0.56      3472\n",
      "\n",
      "    accuracy                           0.81     13237\n",
      "   macro avg       0.78      0.70      0.72     13237\n",
      "weighted avg       0.80      0.81      0.80     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming best_params are already known from your previous GridSearch\n",
    "best_params = {'C': 0.1, 'penalty': 'l1'}  # Replace with your actual best parameters\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow'].astype('int')  # Ensure y is of integer type\n",
    "\n",
    "# Splitting the data into a 70% training set and a 30% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model with the best parameters\n",
    "logreg_optimized = LogisticRegression(**best_params, solver='liblinear', random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the new test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluating the model on the new test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy of Optimized Model on New Test Set:\", accuracy)\n",
    "print(\"Classification Report for New Test Set:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search (Decision Tree): {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Score from Grid Search on Validation Set (Decision Tree): 0.7796931125588873\n",
      "Accuracy of Optimized Decision Tree Model on Test Set: 0.7995013975976429\n",
      "Classification Report for Test Set (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      9765\n",
      "           1       0.67      0.46      0.55      3472\n",
      "\n",
      "    accuracy                           0.80     13237\n",
      "   macro avg       0.75      0.69      0.71     13237\n",
      "weighted avg       0.79      0.80      0.79     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid_dtree = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search_dtree = GridSearchCV(dtree, param_grid_dtree, cv=5, scoring='accuracy')\n",
    "grid_search_dtree.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params_dtree = grid_search_dtree.best_params_\n",
    "best_score_dtree = grid_search_dtree.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "dtree_optimized = DecisionTreeClassifier(**best_params_dtree, random_state=42)\n",
    "dtree_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dtree = dtree_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy_dtree = accuracy_score(y_test, y_pred_dtree)\n",
    "classification_rep_dtree = classification_report(y_test, y_pred_dtree)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search (Decision Tree):\", best_params_dtree)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set (Decision Tree):\", best_score_dtree)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Decision Tree Model on Test Set:\", accuracy_dtree)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set (Decision Tree):\")\n",
    "print(classification_rep_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Optimized Model on New Test Set: 0.7995013975976429\n",
      "Classification Report for New Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      9765\n",
      "           1       0.67      0.46      0.55      3472\n",
      "\n",
      "    accuracy                           0.80     13237\n",
      "   macro avg       0.75      0.69      0.71     13237\n",
      "weighted avg       0.79      0.80      0.79     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}  # Replace with your actual best parameters\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow'].astype('int')  # Ensure y is of integer type\n",
    "\n",
    "# Splitting the data into a 70% training set and a 30% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model with the best parameters\n",
    "logreg_optimized = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the new test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluating the model on the new test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy of Optimized Model on New Test Set:\", accuracy)\n",
    "print(\"Classification Report for New Test Set:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search (Decision Tree): {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score from Grid Search on Validation Set (Decision Tree): 0.8159555665166367\n",
      "Accuracy of Optimized Decision Tree Model on Test Set: 0.8261690715418901\n",
      "Classification Report for Test Set (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      9765\n",
      "           1       0.75      0.50      0.60      3472\n",
      "\n",
      "    accuracy                           0.83     13237\n",
      "   macro avg       0.80      0.72      0.75     13237\n",
      "weighted avg       0.82      0.83      0.81     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_score_rf = grid_search_rf.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "rf_optimized = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search (Decision Tree):\", best_params_rf)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set (Decision Tree):\", best_score_rf)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Decision Tree Model on Test Set:\", accuracy_rf)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set (Decision Tree):\")\n",
    "print(classification_rep_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Optimized Model on New Test Set: 0.8261690715418901\n",
      "Classification Report for New Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      9765\n",
      "           1       0.75      0.50      0.60      3472\n",
      "\n",
      "    accuracy                           0.83     13237\n",
      "   macro avg       0.80      0.72      0.75     13237\n",
      "weighted avg       0.82      0.83      0.81     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} # Replace with your actual best parameters\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow'].astype('int')  # Ensure y is of integer type\n",
    "\n",
    "# Splitting the data into a 70% training set and a 30% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model with the best parameters\n",
    "logreg_optimized = RandomForestClassifier(**best_params, random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the new test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluating the model on the new test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy of Optimized Model on New Test Set:\", accuracy)\n",
    "print(\"Classification Report for New Test Set:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16048\\1763893344.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming coastal_data is your preprocessed dataset\n",
    "X = coastal_data.drop(['RainTomorrow'], axis=1)\n",
    "y = coastal_data['RainTomorrow']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Building the revised model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train_scaled.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer for regularization\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Another dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model with a different optimizer and learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the model with more epochs and early stopping\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, \n",
    "                    validation_data=(X_val_scaled, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the revised model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred_classes = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Compute classification report\n",
    "classification_rep = classification_report(y_test, y_pred_classes)\n",
    "\n",
    "# Print the accuracy and the detailed classification report\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.94      0.88      4860\n",
      "         1.0       0.75      0.46      0.57      1759\n",
      "\n",
      "    accuracy                           0.82      6619\n",
      "   macro avg       0.79      0.70      0.73      6619\n",
      "weighted avg       0.81      0.82      0.80      6619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming coastal_data is your preprocessed dataset\n",
    "X = coastal_data.drop(['RainTomorrow'], axis=1)\n",
    "y = coastal_data['RainTomorrow']\n",
    "\n",
    "# Split the data into training and test sets (70% training, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32))\n",
    "X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "y_test_tensor = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model definition\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train_scaled.shape[1], 128)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = NeuralNet()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()  # Adjusting the output shape\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs).squeeze()  # Adjusting the output shape\n",
    "        y_pred.extend(outputs.round().numpy())\n",
    "\n",
    "# Convert predictions to a format suitable for classification report\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "\n",
    "# Compute classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
