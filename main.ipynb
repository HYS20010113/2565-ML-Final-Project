{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Row0</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Row1</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Row2</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row3</td>\n",
       "      <td>Albury</td>\n",
       "      <td>14.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>56.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>1005.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.6</td>\n",
       "      <td>28.9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Row4</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>35.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1013.4</td>\n",
       "      <td>1010.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.3</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  row ID Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine   \n",
       "0   Row0   Albury     13.4     22.9       0.6          NaN       NaN  \\\n",
       "1   Row1   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2   Row2   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "3   Row3   Albury     14.6     29.7       0.2          NaN       NaN   \n",
       "4   Row4   Albury      7.7     26.7       0.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm   \n",
       "0           W           44.0          W  ...        71.0         22.0  \\\n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2           W           41.0        ENE  ...        82.0         33.0   \n",
       "3         WNW           56.0          W  ...        55.0         23.0   \n",
       "4           W           35.0        SSE  ...        48.0         19.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday   \n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No  \\\n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "3       1009.2       1005.4       NaN       NaN     20.6     28.9         No   \n",
       "4       1013.4       1010.1       NaN       NaN     16.3     25.5         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Weather Training Data.csv'\n",
    "# Loading the dataset again to work with the original 'Location' values (string names)\n",
    "weather_data_original = pd.read_csv(file_path)\n",
    "\n",
    "# Filtering the dataset to focus only on observations from 'Albury'\n",
    "weather_data_albury = weather_data_original[weather_data_original['Location'] == 'Albury']\n",
    "\n",
    "weather_data_albury.head()\n",
    "\n",
    "\n",
    "# # Display the first few rows of the dataset and its summary\n",
    "# weather_data.head(), weather_data.describe(), weather_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/impute/_base.py:558: UserWarning: Skipping features without any observed values: ['Evaporation' 'Sunshine']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/xinranli/Desktop/2565-ML-Final-Project/main.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinranli/Desktop/2565-ML-Final-Project/main.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m numeric_columns \u001b[39m=\u001b[39m weather_data_albury\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mnumber])\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinranli/Desktop/2565-ML-Final-Project/main.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m imputer_numeric \u001b[39m=\u001b[39m SimpleImputer(strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xinranli/Desktop/2565-ML-Final-Project/main.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m weather_data_albury[numeric_columns] \u001b[39m=\u001b[39m imputer_numeric\u001b[39m.\u001b[39mfit_transform(weather_data_albury[numeric_columns])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinranli/Desktop/2565-ML-Final-Project/main.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# For categorical columns, we'll impute missing values with the mode (most frequent value) of the column\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinranli/Desktop/2565-ML-Final-Project/main.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m categorical_columns \u001b[39m=\u001b[39m weather_data_albury\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3947\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3945\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   3946\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (Series, np\u001b[39m.\u001b[39mndarray, \u001b[39mlist\u001b[39m, Index)):\n\u001b[0;32m-> 3947\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_array(key, value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   3949\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3998\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3995\u001b[0m         \u001b[39mself\u001b[39m[col] \u001b[39m=\u001b[39m value\n\u001b[1;32m   3997\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 3998\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iset_not_inplace(key, value)\n\u001b[1;32m   4000\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39mndim(value) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4001\u001b[0m     \u001b[39m# list of lists\u001b[39;00m\n\u001b[1;32m   4002\u001b[0m     value \u001b[39m=\u001b[39m DataFrame(value)\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4025\u001b[0m, in \u001b[0;36mDataFrame._iset_not_inplace\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4023\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m   4024\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mshape(value)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(key):\n\u001b[0;32m-> 4025\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mColumns must be same length as key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4027\u001b[0m     \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(key):\n\u001b[1;32m   4028\u001b[0m         \u001b[39mself\u001b[39m[col] \u001b[39m=\u001b[39m igetitem(value, i)\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Handling missing values\n",
    "# For numeric columns, we'll impute missing values with the mean of the column\n",
    "numeric_columns = weather_data_albury.select_dtypes(include=[np.number]).columns\n",
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "weather_data_albury[numeric_columns] = imputer_numeric.fit_transform(weather_data_albury[numeric_columns])\n",
    "\n",
    "# For categorical columns, we'll impute missing values with the mode (most frequent value) of the column\n",
    "categorical_columns = weather_data_albury.select_dtypes(include=['object']).columns\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "weather_data_albury[categorical_columns] = imputer_categorical.fit_transform(weather_data_albury[categorical_columns])\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    weather_data_albury[column] = label_encoders[column].fit_transform(weather_data_albury[column])\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = StandardScaler()\n",
    "weather_data_albury[numeric_columns] = scaler.fit_transform(weather_data_albury[numeric_columns])\n",
    "\n",
    "# # Check the preprocessed data\n",
    "# weather_data.head(), weather_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training set size': 69661,\n",
       " 'Validation set size': 14927,\n",
       " 'Test set size': 14928}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = weather_data_albury.drop(columns=['RainTomorrow'])\n",
    "y = weather_data_albury['RainTomorrow']\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "# Using 70% of data for training, 15% for validation, and 15% for testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "# Sizes of each dataset\n",
    "sizes = {\n",
    "    \"Training set size\": X_train.shape[0],\n",
    "    \"Validation set size\": X_val.shape[0],\n",
    "    \"Test set size\": X_test.shape[0]\n",
    "}\n",
    "\n",
    "sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search: {'C': 1, 'penalty': 'l1'}\n",
      "Best Score from Grid Search on Validation Set: 0.842030559136383\n",
      "Accuracy of Optimized Model on Test Set: 0.8413049303322615\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90     11493\n",
      "           1       0.73      0.49      0.59      3435\n",
      "\n",
      "    accuracy                           0.84     14928\n",
      "   macro avg       0.80      0.72      0.74     14928\n",
      "weighted avg       0.83      0.84      0.83     14928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'] # Norm used in the penalization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "logreg_optimized = LogisticRegression(**best_params, solver='liblinear', random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search:\", best_params)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set:\", best_score)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Model on Test Set:\", accuracy)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score from Grid Search on Validation Set for SVM: 0.7763113850116848\n",
      "Accuracy of Optimized SVM Model on Test Set: 0.769895498392283\n",
      "Classification Report for Test Set using SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     11493\n",
      "           1       0.00      0.00      0.00      3435\n",
      "\n",
      "    accuracy                           0.77     14928\n",
      "   macro avg       0.38      0.50      0.43     14928\n",
      "weighted avg       0.59      0.77      0.67     14928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the Support Vector Machine classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    # 'kernel': ['rbf', 'poly'],  # Kernel types\n",
    "    'kernel': ['rbf'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search_svm = GridSearchCV(svm_classifier, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_score_svm = grid_search_svm.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "svm_optimized = SVC(**best_params_svm, random_state=42)\n",
    "svm_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search for SVM:\", best_params_svm)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set for SVM:\", best_score_svm)\n",
    "\n",
    "# Printing the accuracy of the optimized SVM model on the test set\n",
    "print(\"Accuracy of Optimized SVM Model on Test Set:\", accuracy_svm)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions by the SVM model\n",
    "print(\"Classification Report for Test Set using SVM:\")\n",
    "print(classification_rep_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
