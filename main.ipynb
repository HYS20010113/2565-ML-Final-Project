{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Weather Training Data.csv'\n",
    "# Loading the dataset again to work with the original 'Location' values (string names)\n",
    "weather_data = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>59784</td>\n",
       "      <td>11</td>\n",
       "      <td>16.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>1002.3</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>59795</td>\n",
       "      <td>11</td>\n",
       "      <td>22.8</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1010.9</td>\n",
       "      <td>1011.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>59805</td>\n",
       "      <td>11</td>\n",
       "      <td>14.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>59816</td>\n",
       "      <td>11</td>\n",
       "      <td>15.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>59827</td>\n",
       "      <td>11</td>\n",
       "      <td>22.7</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1009.4</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row ID  Location  MinTemp  MaxTemp  Rainfall  WindGustDir   \n",
       "6273   59784        11     16.1     31.4       0.0            5  \\\n",
       "6274   59795        11     22.8     24.7       0.0           11   \n",
       "6275   59805        11     14.8     25.0       0.8            0   \n",
       "6276   59816        11     15.5     27.3       0.0            4   \n",
       "6277   59827        11     22.7     29.2       0.0           11   \n",
       "\n",
       "      WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  WindSpeed3pm   \n",
       "6273           54.0           3           5           7.0          37.0  \\\n",
       "6274           56.0          11           8          35.0          15.0   \n",
       "6275           24.0          10           2           7.0          17.0   \n",
       "6276           41.0           7           4           7.0          30.0   \n",
       "6277           44.0           7           5           9.0          20.0   \n",
       "\n",
       "      Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm   \n",
       "6273         51.0         58.0       1005.9       1002.3     26.5     28.4  \\\n",
       "6274         68.0         67.0       1010.9       1011.4     23.4     24.4   \n",
       "6275         62.0         45.0       1019.5       1017.0     22.5     24.8   \n",
       "6276         54.0         62.0       1015.7       1012.7     24.6     26.1   \n",
       "6277         70.0         71.0       1009.4       1008.8     25.8     26.4   \n",
       "\n",
       "      RainToday  RainTomorrow  \n",
       "6273          0           0.0  \n",
       "6274          0           1.0  \n",
       "6275          0           0.0  \n",
       "6276          0           0.0  \n",
       "6277          0           1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing steps for the whole dataset\n",
    "\n",
    "# # Dropping 'row ID' as it's not needed for model training\n",
    "# weather_data = weather_data.drop(['row ID'], axis=1)\n",
    "\n",
    "# Handling missing values for numerical columns\n",
    "num_cols = weather_data.select_dtypes(include=[np.number]).columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "weather_data[num_cols] = imputer_num.fit_transform(weather_data[num_cols])\n",
    "\n",
    "# Handling missing values for categorical columns\n",
    "# For now, we will drop columns with a high percentage of missing values\n",
    "weather_data = weather_data.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1)\n",
    "cat_cols = weather_data.select_dtypes(include=['object']).columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "weather_data[cat_cols] = imputer_cat.fit_transform(weather_data[cat_cols])\n",
    "\n",
    "\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for column in cat_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    weather_data[column] = label_encoder.fit_transform(weather_data[column].astype(str))\n",
    "    label_encoders[column] = label_encoder\n",
    "\n",
    "# Adjusting the provided code to extract data for all coastal cities in Australia\n",
    "\n",
    "# First, let's define the coastal cities as per the original dataset\n",
    "coastal_cities = ['Adelaide', 'Albany', 'Brisbane', 'Cairns', 'CoffsHarbour', \n",
    "                  'Darwin', 'GoldCoast', 'Hobart', 'Melbourne', 'MelbourneAirport',\n",
    "                  'Newcastle', 'NorahHead', 'NorfolkIsland', 'Perth', 'PerthAirport',\n",
    "                  'Portland', 'Sydney', 'SydneyAirport', 'Townsville', 'Williamtown', 'Wollongong']\n",
    "\n",
    "# Now, let's extract the encoded values for these coastal cities\n",
    "encoded_coastal_cities = {label_encoders['Location'].transform([city])[0] for city in coastal_cities if city in label_encoders['Location'].classes_}\n",
    "\n",
    "# Extracting data for these coastal cities\n",
    "coastal_data = weather_data[weather_data['Location'].isin(encoded_coastal_cities)]\n",
    "\n",
    "# Overview of the processed coastal cities data\n",
    "coastal_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the encoded integer values back to their original string labels in 'Location' column\n",
    "location_mappings = {index: label for index, label in enumerate(label_encoders['Location'].classes_)}\n",
    "# location_mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training set size': 30885,\n",
       " 'Validation set size': 6618,\n",
       " 'Test set size': 6619}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow']\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "# Using 70% of data for training, 15% for validation, and 15% for testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "# Sizes of each dataset\n",
    "sizes = {\n",
    "    \"Training set size\": X_train.shape[0],\n",
    "    \"Validation set size\": X_val.shape[0],\n",
    "    \"Test set size\": X_test.shape[0]\n",
    "}\n",
    "\n",
    "sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search: {'C': 0.1, 'penalty': 'l1'}\n",
      "Best Score from Grid Search on Validation Set: 0.8136900480232375\n",
      "Accuracy of Optimized Model on Test Set: 0.8116029611723825\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4860\n",
      "           1       0.72      0.47      0.57      1759\n",
      "\n",
      "    accuracy                           0.81      6619\n",
      "   macro avg       0.78      0.70      0.72      6619\n",
      "weighted avg       0.80      0.81      0.80      6619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'] # Norm used in the penalization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "logreg_optimized = LogisticRegression(**best_params, solver='liblinear', random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search:\", best_params)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set:\", best_score)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Model on Test Set:\", accuracy)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search for SVM: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Score from Grid Search on Validation Set for SVM: 0.7763113850116848\n",
      "Accuracy of Optimized SVM Model on Test Set: 0.769895498392283\n",
      "Classification Report for Test Set using SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     11493\n",
      "           1       0.00      0.00      0.00      3435\n",
      "\n",
      "    accuracy                           0.77     14928\n",
      "   macro avg       0.38      0.50      0.43     14928\n",
      "weighted avg       0.59      0.77      0.67     14928\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/xinranli/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the Support Vector Machine classifier\n",
    "svm_classifier = SVC(random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    # 'kernel': ['rbf', 'poly'],  # Kernel types\n",
    "    'kernel': ['rbf'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search_svm = GridSearchCV(svm_classifier, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params_svm = grid_search_svm.best_params_\n",
    "best_score_svm = grid_search_svm.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "svm_optimized = SVC(**best_params_svm, random_state=42)\n",
    "svm_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "classification_rep_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search for SVM:\", best_params_svm)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set for SVM:\", best_score_svm)\n",
    "\n",
    "# Printing the accuracy of the optimized SVM model on the test set\n",
    "print(\"Accuracy of Optimized SVM Model on Test Set:\", accuracy_svm)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions by the SVM model\n",
    "print(\"Classification Report for Test Set using SVM:\")\n",
    "print(classification_rep_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
