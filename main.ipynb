{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Weather Training Data.csv'\n",
    "# Loading the dataset again to work with the original 'Location' values (string names)\n",
    "weather_data = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>59784</td>\n",
       "      <td>11</td>\n",
       "      <td>16.1</td>\n",
       "      <td>31.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>1002.3</td>\n",
       "      <td>26.5</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6274</th>\n",
       "      <td>59795</td>\n",
       "      <td>11</td>\n",
       "      <td>22.8</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1010.9</td>\n",
       "      <td>1011.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6275</th>\n",
       "      <td>59805</td>\n",
       "      <td>11</td>\n",
       "      <td>14.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>59816</td>\n",
       "      <td>11</td>\n",
       "      <td>15.5</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>1012.7</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6277</th>\n",
       "      <td>59827</td>\n",
       "      <td>11</td>\n",
       "      <td>22.7</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1009.4</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row ID  Location  MinTemp  MaxTemp  Rainfall  WindGustDir  \\\n",
       "6273   59784        11     16.1     31.4       0.0            5   \n",
       "6274   59795        11     22.8     24.7       0.0           11   \n",
       "6275   59805        11     14.8     25.0       0.8            0   \n",
       "6276   59816        11     15.5     27.3       0.0            4   \n",
       "6277   59827        11     22.7     29.2       0.0           11   \n",
       "\n",
       "      WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  WindSpeed3pm  \\\n",
       "6273           54.0           3           5           7.0          37.0   \n",
       "6274           56.0          11           8          35.0          15.0   \n",
       "6275           24.0          10           2           7.0          17.0   \n",
       "6276           41.0           7           4           7.0          30.0   \n",
       "6277           44.0           7           5           9.0          20.0   \n",
       "\n",
       "      Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm  \\\n",
       "6273         51.0         58.0       1005.9       1002.3     26.5     28.4   \n",
       "6274         68.0         67.0       1010.9       1011.4     23.4     24.4   \n",
       "6275         62.0         45.0       1019.5       1017.0     22.5     24.8   \n",
       "6276         54.0         62.0       1015.7       1012.7     24.6     26.1   \n",
       "6277         70.0         71.0       1009.4       1008.8     25.8     26.4   \n",
       "\n",
       "      RainToday  RainTomorrow  \n",
       "6273          0           0.0  \n",
       "6274          0           1.0  \n",
       "6275          0           0.0  \n",
       "6276          0           0.0  \n",
       "6277          0           1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing steps for the whole dataset\n",
    "\n",
    "# # Dropping 'row ID' as it's not needed for model training\n",
    "# weather_data = weather_data.drop(['row ID'], axis=1)\n",
    "\n",
    "# Handling missing values for numerical columns\n",
    "num_cols = weather_data.select_dtypes(include=[np.number]).columns\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "weather_data[num_cols] = imputer_num.fit_transform(weather_data[num_cols])\n",
    "\n",
    "# Handling missing values for categorical columns\n",
    "# For now, we will drop columns with a high percentage of missing values\n",
    "weather_data = weather_data.drop(['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm'], axis=1)\n",
    "cat_cols = weather_data.select_dtypes(include=['object']).columns\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "weather_data[cat_cols] = imputer_cat.fit_transform(weather_data[cat_cols])\n",
    "\n",
    "\n",
    "\n",
    "# Encoding categorical variables\n",
    "label_encoders = {}\n",
    "for column in cat_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    weather_data[column] = label_encoder.fit_transform(weather_data[column].astype(str))\n",
    "    label_encoders[column] = label_encoder\n",
    "\n",
    "# Adjusting the provided code to extract data for all coastal cities in Australia\n",
    "\n",
    "# First, let's define the coastal cities as per the original dataset\n",
    "coastal_cities = ['Adelaide', 'Albany', 'Brisbane', 'Cairns', 'CoffsHarbour', \n",
    "                  'Darwin', 'GoldCoast', 'Hobart', 'Melbourne', 'MelbourneAirport',\n",
    "                  'Newcastle', 'NorahHead', 'NorfolkIsland', 'Perth', 'PerthAirport',\n",
    "                  'Portland', 'Sydney', 'SydneyAirport', 'Townsville', 'Williamtown', 'Wollongong']\n",
    "\n",
    "# Now, let's extract the encoded values for these coastal cities\n",
    "encoded_coastal_cities = {label_encoders['Location'].transform([city])[0] for city in coastal_cities if city in label_encoders['Location'].classes_}\n",
    "\n",
    "# Extracting data for these coastal cities\n",
    "coastal_data = weather_data[weather_data['Location'].isin(encoded_coastal_cities)]\n",
    "\n",
    "# Overview of the processed coastal cities data\n",
    "coastal_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the encoded integer values back to their original string labels in 'Location' column\n",
    "location_mappings = {index: label for index, label in enumerate(label_encoders['Location'].classes_)}\n",
    "# location_mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Training set size': 30885,\n",
       " 'Validation set size': 6618,\n",
       " 'Test set size': 6619}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow']\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "# Using 70% of data for training, 15% for validation, and 15% for testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_val = y_val.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "# Sizes of each dataset\n",
    "sizes = {\n",
    "    \"Training set size\": X_train.shape[0],\n",
    "    \"Validation set size\": X_val.shape[0],\n",
    "    \"Test set size\": X_test.shape[0]\n",
    "}\n",
    "\n",
    "sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search: {'C': 0.1, 'penalty': 'l1'}\n",
      "Best Score from Grid Search on Validation Set: 0.8136900480232375\n",
      "Accuracy of Optimized Model on Test Set: 0.8116029611723825\n",
      "Classification Report for Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4860\n",
      "           1       0.72      0.47      0.57      1759\n",
      "\n",
      "    accuracy                           0.81      6619\n",
      "   macro avg       0.78      0.70      0.72      6619\n",
      "weighted avg       0.80      0.81      0.80      6619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100], # Regularization parameter\n",
    "    'penalty': ['l1', 'l2'] # Norm used in the penalization\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "logreg_optimized = LogisticRegression(**best_params, solver='liblinear', random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search:\", best_params)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set:\", best_score)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Model on Test Set:\", accuracy)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set:\")\n",
    "print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Optimized Model on New Test Set: 0.8133262823902697\n",
      "Classification Report for New Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      9765\n",
      "           1       0.73      0.46      0.56      3472\n",
      "\n",
      "    accuracy                           0.81     13237\n",
      "   macro avg       0.78      0.70      0.72     13237\n",
      "weighted avg       0.80      0.81      0.80     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming best_params are already known from your previous GridSearch\n",
    "best_params = {'C': 0.1, 'penalty': 'l1'}  # Replace with your actual best parameters\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow'].astype('int')  # Ensure y is of integer type\n",
    "\n",
    "# Splitting the data into a 70% training set and a 30% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model with the best parameters\n",
    "logreg_optimized = LogisticRegression(**best_params, solver='liblinear', random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the new test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluating the model on the new test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy of Optimized Model on New Test Set:\", accuracy)\n",
    "print(\"Classification Report for New Test Set:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search (Decision Tree): {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best Score from Grid Search on Validation Set (Decision Tree): 0.7796931125588873\n",
      "Accuracy of Optimized Decision Tree Model on Test Set: 0.7995013975976429\n",
      "Classification Report for Test Set (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      9765\n",
      "           1       0.67      0.46      0.55      3472\n",
      "\n",
      "    accuracy                           0.80     13237\n",
      "   macro avg       0.75      0.69      0.71     13237\n",
      "weighted avg       0.79      0.80      0.79     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid_dtree = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search_dtree = GridSearchCV(dtree, param_grid_dtree, cv=5, scoring='accuracy')\n",
    "grid_search_dtree.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params_dtree = grid_search_dtree.best_params_\n",
    "best_score_dtree = grid_search_dtree.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "dtree_optimized = DecisionTreeClassifier(**best_params_dtree, random_state=42)\n",
    "dtree_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dtree = dtree_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy_dtree = accuracy_score(y_test, y_pred_dtree)\n",
    "classification_rep_dtree = classification_report(y_test, y_pred_dtree)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search (Decision Tree):\", best_params_dtree)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set (Decision Tree):\", best_score_dtree)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Decision Tree Model on Test Set:\", accuracy_dtree)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set (Decision Tree):\")\n",
    "print(classification_rep_dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Optimized Model on New Test Set: 0.7995013975976429\n",
      "Classification Report for New Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      9765\n",
      "           1       0.67      0.46      0.55      3472\n",
      "\n",
      "    accuracy                           0.80     13237\n",
      "   macro avg       0.75      0.69      0.71     13237\n",
      "weighted avg       0.79      0.80      0.79     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2}  # Replace with your actual best parameters\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow'].astype('int')  # Ensure y is of integer type\n",
    "\n",
    "# Splitting the data into a 70% training set and a 30% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model with the best parameters\n",
    "logreg_optimized = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the new test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluating the model on the new test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy of Optimized Model on New Test Set:\", accuracy)\n",
    "print(\"Classification Report for New Test Set:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from Grid Search (Decision Tree): {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Score from Grid Search on Validation Set (Decision Tree): 0.8159555665166367\n",
      "Accuracy of Optimized Decision Tree Model on Test Set: 0.8261690715418901\n",
      "Classification Report for Test Set (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      9765\n",
      "           1       0.75      0.50      0.60      3472\n",
      "\n",
      "    accuracy                           0.83     13237\n",
      "   macro avg       0.80      0.72      0.75     13237\n",
      "weighted avg       0.82      0.83      0.81     13237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Parameters for tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation for parameter tuning\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "grid_search_rf.fit(X_val, y_val)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "best_score_rf = grid_search_rf.best_score_\n",
    "\n",
    "# Train the model with the best parameters on the full training set\n",
    "rf_optimized = RandomForestClassifier(**best_params_rf, random_state=42)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the optimized model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "# Printing the best parameters found by Grid Search\n",
    "print(\"Best Parameters from Grid Search (Decision Tree):\", best_params_rf)\n",
    "\n",
    "# Printing the best score achieved on the validation set during Grid Search\n",
    "print(\"Best Score from Grid Search on Validation Set (Decision Tree):\", best_score_rf)\n",
    "\n",
    "# Printing the accuracy of the optimized model on the test set\n",
    "print(\"Accuracy of Optimized Decision Tree Model on Test Set:\", accuracy_rf)\n",
    "\n",
    "# Printing the detailed classification report for the test set predictions\n",
    "print(\"Classification Report for Test Set (Decision Tree):\")\n",
    "print(classification_rep_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} # Replace with your actual best parameters\n",
    "\n",
    "# Splitting the dataset into features (X) and target variable (y)\n",
    "X = coastal_data.drop(columns=['RainTomorrow'])\n",
    "y = coastal_data['RainTomorrow'].astype('int')  # Ensure y is of integer type\n",
    "\n",
    "# Splitting the data into a 70% training set and a 30% test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Training the Logistic Regression model with the best parameters\n",
    "logreg_optimized = RandomForestClassifier(**best_params, random_state=42)\n",
    "logreg_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the new test set\n",
    "y_pred = logreg_optimized.predict(X_test)\n",
    "\n",
    "# Evaluating the model on the new test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy of Optimized Model on New Test Set:\", accuracy)\n",
    "print(\"Classification Report for New Test Set:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33040\\1763893344.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming coastal_data is your preprocessed dataset\n",
    "X = coastal_data.drop(['RainTomorrow'], axis=1)\n",
    "y = coastal_data['RainTomorrow']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Building the revised model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train_scaled.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer for regularization\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Another dropout layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the model with a different optimizer and learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Training the model with more epochs and early stopping\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, \n",
    "                    validation_data=(X_val_scaled, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the revised model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred_classes = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Compute classification report\n",
    "classification_rep = classification_report(y_test, y_pred_classes)\n",
    "\n",
    "# Print the accuracy and the detailed classification report\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
